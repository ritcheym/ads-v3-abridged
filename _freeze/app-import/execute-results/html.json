{
  "hash": "0e9878bc47de60b639e5482038e8e976",
  "result": {
    "markdown": "# Data Import {#sec-data}\n\nTHIS APPENDIX IS BEING UPDATED...\n\n## Intended Learning Outcomes {#sec-ilo-data .unnumbered}\n\n* Be able to inspect data\n* Be able to import data from a range of sources\n* Be able to identify and handle common problems with data import\n\n## Walkthrough video {#sec-walkthrough-data .unnumbered}\n\nThere is a walkthrough video of this chapter available via [Echo360.](https://echo360.org.uk/media/52d2249e-a737-42b4-bf55-267e39fc05c5/public) Please note that there may have been minor edits to the book since the video was recorded. Where there are differences, the book should always take precedence.\n\n## Set-up {#sec-setup-data}\n\nCreate a new project for the work we'll do in this chapter named <code class='path'>04-data</code>. Then, create and save a new R Markdown document named `data.Rmd`, get rid of the default template text, and load the packages in the set-up code chunk. You should have all of these packages installed already, but if you get the message `Error in library(x) : there is no package called ‘x’`, please refer to @sec-install-package.\n\n\n::: {.cell layout-align=\"center\" verbatim='r setup, include=FALSE'}\n<div class='verbatim'><pre class='sourceCode r'><code class='sourceCode R'>&#96;&#96;&#96;{r setup, include=FALSE}</code></pre>\n\n```{.r .cell-code}\nlibrary(tidyverse)     # includes readr & tibble\nlibrary(rio)           # for almost any data import/export\nlibrary(haven)         # for SPSS, Stata,and SAS files\nlibrary(readxl)        # for Excel files\nlibrary(googlesheets4) # for Google Sheets\n```\n\n<pre class='sourceCode r'><code class='sourceCode R'>&#96;&#96;&#96;</code></pre></div>\n:::\n\n\nWe'd recommend making a new code chunk for each different activity, and using the white space to make notes on any errors you make, things you find interesting, or questions you'd like to ask the course team.\n\nDownload the [Data import cheatsheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-import.pdf).\n\n## Built-in data {#sec-builtin}\n\nYou'll likely want to import you own data to work with, however, Base R also comes with built-in datasets and these can be very useful for learning new functions and packages. Additionally, some packages, like <pkg>tidyr</pkg>, also contain data. The `data()` function lists the datasets available.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# list datasets built in to base R\ndata()\n\n# lists datasets in a specific package\ndata(package = \"tidyr\")\n```\n:::\n\n\nType the name of a dataset into the <a class='glossary'>console<span class='def'></span></a> to see the data. For example, type `?table1` into the console to see the dataset description for `table1`, which is a dataset included with <pkg>tidyr</pkg>.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n?table1\n```\n:::\n\n\nYou can also use the `data()` function to load a dataset into your <a class='glossary'>global environment<span class='def'></span></a>.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# loads table1 into the environment\ndata(\"table1\")\n```\n:::\n\n\n\n## Looking at data\n\nNow that you've loaded some data, look the upper right hand window of RStudio, under the Environment tab. You will see the object `table1` listed, along with the number of observations (rows) and variables (columns). This is your first check that everything went OK.\n\n**Always, always, always, look at your data once you've created or loaded a table**. Also look at it after each step that transforms your table. There are three main ways to look at your table: `View()`, `print()`, `tibble::glimpse()`. \n\n### View() \n\nA familiar way to look at the table is given by `View()` (uppercase 'V'), which opens up a data table in the console pane using a viewer that looks a bit like Excel. This command can be useful in the console, but don't ever put this one in a script because it will create an annoying pop-up window when the user runs it. You can also click on an object in the  <a class='glossary'>environment pane<span class='def'></span></a> to open it in the same interface. You can close the tab when you're done looking at it; it won't remove the object.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nView(table1)\n```\n:::\n\n\n\n### print() \n\nThe `print()` method can be run explicitly, but is more commonly called by just typing the variable name on a blank line. The default is not to print the entire table, but just the first 10 rows. \n\nLet's look at the `table1` table that we loaded above. Depending on how wide your screen is, you might need to click on an arrow at the right of the table to see the last column. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# call print explicitly\nprint(table1)\n\n# more common method of just calling object name\ntable1\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|country     | year|  cases| population|\n|:-----------|----:|------:|----------:|\n|Afghanistan | 1999|    745|   19987071|\n|Afghanistan | 2000|   2666|   20595360|\n|Brazil      | 1999|  37737|  172006362|\n|Brazil      | 2000|  80488|  174504898|\n|China       | 1999| 212258| 1272915272|\n|China       | 2000| 213766| 1280428583|\n\n</div>\n:::\n:::\n\n\n### glimpse() \n\nThe function `tibble::glimpse()` gives a sideways version of the table. This is useful if the table is very wide and you can't easily see all of the columns. It also tells you the <a class='glossary'>data type<span class='def'></span></a> of each column in angled brackets after each column name. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglimpse(table1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 6\nColumns: 4\n$ country    <chr> \"Afghanistan\", \"Afghanistan\", \"Brazil\", \"Brazil\", \"China\", …\n$ year       <dbl> 1999, 2000, 1999, 2000, 1999, 2000\n$ cases      <dbl> 745, 2666, 37737, 80488, 212258, 213766\n$ population <dbl> 19987071, 20595360, 172006362, 174504898, 1272915272, 12804…\n```\n:::\n:::\n\n\n### summary() {#sec-summary-function}\n\nYou can get a quick summary of a dataset with the `summary()` function, which can be useful for spotting things like if the minimum or maximum values are clearly wrong, or if R thinks that a <a class='glossary'>nominal<span class='def'></span></a> variable is <a class='glossary'>numeric<span class='def'></span></a>. For example, if you had labelled gender as 1, 2, and 3 rather than male, female, and non-binary, `summary()` would calculate a mean and median even though this isn't appropriate for the data. This can be a useful flag that you need to take further steps to correct your data. \n\nNote that because `population` is a very, very large number, R will use [scientific notation](https://courses.lumenlearning.com/waymakerintermediatealgebra/chapter/read-writing-scientific-notation-2/). \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(table1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   country               year          cases          population       \n Length:6           Min.   :1999   Min.   :   745   Min.   :1.999e+07  \n Class :character   1st Qu.:1999   1st Qu.: 11434   1st Qu.:5.845e+07  \n Mode  :character   Median :2000   Median : 59112   Median :1.733e+08  \n                    Mean   :2000   Mean   : 91277   Mean   :4.901e+08  \n                    3rd Qu.:2000   3rd Qu.:179316   3rd Qu.:9.983e+08  \n                    Max.   :2000   Max.   :213766   Max.   :1.280e+09  \n```\n:::\n:::\n\n\n\n## Importing data {#sec-import_data}\n\nBuilt-in data are nice for examples, but you're probably more interested in your own data. There are many different types of files that you might work with when doing data analysis. These different file types are usually distinguished by the three-letter <a class='glossary'>extension<span class='def'></span></a> following a period at the end of the file name (e.g., `.xls`). \n\nDownload this [directory of data files](data/data.zip), unzip the folder, and save the `data` directory in the `04-data` project directory.\n\n\n\n\n\n\n### rio::import()  \n\nThe type of data files you have to work with will likely depend on the software that you typically use in your workflow. The <pkg>rio</pkg> package has very straightforward functions for reading and saving data in most common formats: `rio::import()` and `rio::export()`. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndemo_tsv  <- import(\"data/demo.tsv\")  # tab-separated values\ndemo_csv  <- import(\"data/demo.csv\")  # comma-separated values\ndemo_xls  <- import(\"data/demo.xlsx\") # Excel format\ndemo_sav  <- import(\"data/demo.sav\")  # SPSS format\n```\n:::\n\n\n\n### File type specific import \n\nHowever, it is also useful to know the specific functions that are used to import different file types because it is easier to discover features to deal with complicated cases, such as when you need to skip rows, rename columns, or choose which Excel sheet to use.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndemo_tsv <- readr::read_tsv(\"data/demo.tsv\")\ndemo_csv <- readr::read_csv(\"data/demo.csv\")\ndemo_xls <- readxl::read_excel(\"data/demo.xlsx\")\ndemo_sav <- haven::read_sav(\"data/demo.sav\")\n```\n:::\n\n\n::: {.callout-note .try}\nLook at the help for each function above and read through the Arguments section to see how you can customise import.\n:::\n\nIf you keep data in Google Sheets, you can access it directly from R using `<pkg>googlesheets4\", \"https://googlesheets4.tidyverse.org/\")`. The code below imports data from a [public sheet](https://docs.google.com/spreadsheets/d/16dkq0YL0J7fyAwT1pdgj1bNNrheckAU_2-DKuuM6aGI){target=\"_blank\"}. You can set the `ss` argument to the entire <a class='glossary'>URL<span class='def'></span></a> for the target sheet, or just the section after \"https://docs.google.com/spreadsheets/d/\".\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngs4_deauth() # skip authorisation for public data\n\ndemo_gs4  <- googlesheets4::read_sheet(\n  ss = \"16dkq0YL0J7fyAwT1pdgj1bNNrheckAU_2-DKuuM6aGI\"\n)\n```\n:::\n\n\n\n### Column data types {#sec-col_types}\n\nUse `glimpse()` to see how these different functions imported the data with slightly different data types. This is because the different file types store data slightly differently. For example, SPSS stores factors as numbers, so the `factor` column contains the values 1, 2, 3 rather than `low`, `med`, `high`. It also stores <a class='glossary'>logical<span class='def'></span></a> values as 0 and 1 instead or TRUE and FALSE.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglimpse(demo_csv)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 6\nColumns: 6\n$ character <chr> \"A\", \"B\", \"C\", \"D\", \"E\", \"F\"\n$ factor    <chr> \"high\", \"low\", \"med\", \"high\", \"low\", \"med\"\n$ integer   <dbl> 1, 2, 3, 4, 5, 6\n$ double    <dbl> 1.5, 2.5, 3.5, 4.5, 5.5, 6.5\n$ logical   <lgl> TRUE, TRUE, FALSE, FALSE, NA, TRUE\n$ date      <date> 2024-02-15, 2024-02-14, 2024-02-13, 2024-02-12, 2024-02-11, …\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglimpse(demo_xls)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 6\nColumns: 6\n$ character <chr> \"A\", \"B\", \"C\", \"D\", \"E\", \"F\"\n$ factor    <chr> \"high\", \"low\", \"med\", \"high\", \"low\", \"med\"\n$ integer   <dbl> 1, 2, 3, 4, 5, 6\n$ double    <dbl> 1.5, 2.5, 3.5, 4.5, 5.5, 6.5\n$ logical   <lgl> TRUE, TRUE, FALSE, FALSE, NA, TRUE\n$ date      <dttm> 2024-02-15, 2024-02-14, 2024-02-13, 2024-02-12, 2024-02-11, …\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglimpse(demo_sav)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 6\nColumns: 6\n$ character <chr> \"A\", \"B\", \"C\", \"D\", \"E\", \"F\"\n$ factor    <dbl+lbl> 3, 1, 2, 3, 1, 2\n$ integer   <dbl> 1, 2, 3, 4, 5, 6\n$ double    <dbl> 1.5, 2.5, 3.5, 4.5, 5.5, 6.5\n$ logical   <dbl> 1, 1, 0, 0, NA, 1\n$ date      <date> 2024-02-15, 2024-02-14, 2024-02-13, 2024-02-12, 2024-02-11, …\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglimpse(demo_gs4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 6\nColumns: 6\n$ character <chr> \"A\", \"B\", \"C\", \"D\", \"E\", \"F\"\n$ factor    <chr> \"high\", \"low\", \"med\", \"high\", \"low\", \"med\"\n$ integer   <dbl> 1, 2, 3, 4, 5, 6\n$ double    <dbl> 1.5, 2.5, 3.5, 4.5, 5.5, 6.5\n$ logical   <lgl> TRUE, TRUE, FALSE, FALSE, NA, TRUE\n$ date      <dttm> 2021-11-22, 2021-11-21, 2021-11-20, 2021-11-19, 2021-11-18, …\n```\n:::\n:::\n\n\nThe <pkg>readr</pkg> functions display a message when you import data explaining what <a class='glossary'>data type<span class='def'></span></a> each column is.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndemo <- readr::read_csv(\"data/demo.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 6 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): character, factor\ndbl  (2): integer, double\nlgl  (1): logical\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\nThe \"Column specification\" tells you which <a class='glossary'>data type<span class='def'></span></a> each column is. You can review data types in @sec-data-types. Options are:\n\n* `chr`: <a class='glossary'>character<span class='def'></span></a>\n* `dbl`: <a class='glossary'>double<span class='def'></span></a>\n* `lgl`: <a class='glossary'>logical<span class='def'></span></a>\n* `int`: <a class='glossary'>integer<span class='def'></span></a>\n* `date`: date\n* `dttm`: date/time\n\n`read_csv()` will guess what type of data each variable is and normally it is pretty good at this. However, if it makes a mistake, such as reading the \"date\" column as a <a class='glossary'>character<span class='def'></span></a>, you can manually set the column data types. \n\nFirst, run `spec()` on the dataset which will give you the full column specification that you can copy and paste:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nspec(demo)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncols(\n  character = col_character(),\n  factor = col_character(),\n  integer = col_double(),\n  double = col_double(),\n  logical = col_logical(),\n  date = col_date(format = \"\")\n)\n```\n:::\n:::\n\n\nThen, we create an object using the code we just copied that lists the correct column types. Factor columns will always import as character data types, so you have to set their data type manually with `col_factor()` and set the order of levels with the `levels` argument. Otherwise, the order defaults to the order they appear in the dataset. For our `demo` dataset, we will tell R that the `factor` variable is a factor by using `col_factor()` and we can also specify the order of the levels so that they don't just appear alphabetically. Additionally, we can also specify exactly what format our `date` variable is in using `%Y-%m-%d`.\n\nWe then save this column specification to an object, and then add this to the `col_types` argument when we call `read_csv()`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncorrected_cols <- cols(\n  character = col_character(),\n  factor = col_factor(levels = c(\"low\", \"med\", \"high\")),\n  integer = col_integer(),\n  double = col_double(),\n  logical = col_logical(),\n  date = col_date(format = \"%Y-%m-%d\")\n)\n\ndemo <- readr::read_csv(\"data/demo.csv\", col_types = corrected_cols)\n```\n:::\n\n\n::: {.callout-note}\nFor dates, you might need to set the format your dates are in. See `?strptime` for a list of the codes used to represent different date formats. For example, `\"%d-%b-%y\"` means that the dates are formatted like `31-Jan-21`. \n:::\n\nThe functions from <pkg>readxl</pkg> for loading `.xlsx` sheets have a different, more limited way to specify the column types. You will have to convert factor columns and dates using `mutate()`, which you'll learn about in @sec-wrangle, so most people let `read_excel()` guess data types and don't set the `col_types` argument.\n\nFor SPSS data, whilst `rio::import()` will just read the numeric values of factors and not their labels, the function `read_sav()` from <pkg>haven</pkg> reads both. However, you have to convert factors from a haven-specific \"labelled double\" to a factor (we have no idea why haven doesn't do this for you).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndemo_sav$factor <- haven::as_factor(demo_sav$factor)\n\nglimpse(demo_sav)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 6\nColumns: 6\n$ character <chr> \"A\", \"B\", \"C\", \"D\", \"E\", \"F\"\n$ factor    <fct> high, low, med, high, low, med\n$ integer   <dbl> 1, 2, 3, 4, 5, 6\n$ double    <dbl> 1.5, 2.5, 3.5, 4.5, 5.5, 6.5\n$ logical   <dbl> 1, 1, 0, 0, NA, 1\n$ date      <date> 2024-02-15, 2024-02-14, 2024-02-13, 2024-02-12, 2024-02-11, …\n```\n:::\n:::\n\n\n\n::: {.callout-note}\nThe way you specify column types for <pkg>googlesheets4</pkg> is a little different from <pkg>readr</pkg>, although you can also use the shortcodes described in the help for `read_sheet()` with <pkg>readr</pkg> functions. There is currently no column specification for factors.\n:::\n\n## Creating data \n\nIf you need to create a small data table from scratch in R, use the `tibble::tibble()` function, and type the data right in. The `tibble` package is part of the <a class='glossary'>tidyverse<span class='def'></span></a> package that we loaded at the start of this chapter. \n\nLet's create a small table with the names of three [Avatar](https://en.wikipedia.org/wiki/Avatar:_The_Last_Airbender) characters and their bending type. The `tibble()` function takes <a class='glossary'>arguments<span class='def'></span></a> with the names that you want your columns to have. The values are <a class='glossary'>vectors<span class='def'></span></a> that list the column values in order.\n\nIf you don't know the value for one of the cells, you can enter <a class='glossary'>NA<span class='def'></span></a>, which we have to do for Sokka because he doesn't have any bending ability. If all the values in the column are the same, you can just enter one value and it will be copied for each row.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\navatar <- tibble(\n  name = c(\"Katara\", \"Toph\", \"Sokka\"),\n  bends = c(\"water\", \"earth\", NA),\n  friendly = TRUE\n)\n\n# print it\navatar\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|name   |bends |friendly |\n|:------|:-----|:--------|\n|Katara |water |TRUE     |\n|Toph   |earth |TRUE     |\n|Sokka  |NA    |TRUE     |\n\n</div>\n:::\n:::\n\n\nYou can also use the `tibble::tribble()` function to create a table by row, rather than by column. You start by listing the column names, each preceded by a tilde (`~`), then you list the values for each column, row by row, separated by commas (don't forget a comma at the end of each row).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\navatar_by_row <- tribble(\n  ~name,    ~bends,  ~friendly,\n  \"Katara\", \"water\", TRUE,\n  \"Toph\",   \"earth\", TRUE,\n  \"Sokka\",  NA,      TRUE\n)\n```\n:::\n\n\n::: {.callout-note}\nYou don't have to line up the columns in a tribble, but it can make it easier to spot errors.\n:::\n\nYou may not need to do this very often if you are primarily working with data that you import from spreadsheets, but it is useful to know how to do it anyway.\n\n## Writing data\n\nIf you have data that you want to save, use `rio::export()`, as follows.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nexport(avatar, \"data/avatar.csv\")\n```\n:::\n\n\nThis will save the data in CSV format to your working directory.\n\nWriting to Google Sheets is a little trickier (if you never use Google Sheets feel free to skip this section). Even if a Google Sheet is publicly editable, you can't add data to it without authorising your account. \n\nYou can authorise interactively using the following code (and your own email), which will prompt you to authorise \"Tidyverse API Packages\" the first time you do this. If you don't tick the checkbox authorising it to \"See, edit, create, and delete all your Google Sheets spreadsheets\", the next steps will fail.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# authorise your account \n# this only needs to be done once per script\ngs4_auth(email = \"myemail@gmail.com\")\n\n# create a new sheet\nsheet_id <- gs4_create(name = \"demo-file\", \n                       sheets = \"letters\")\n\n# define the data table to save\nletter_data <- tibble(\n  character = LETTERS[1:5],\n  integer = 1:5,\n  double = c(1.1, 2.2, 3.3, 4.4, 5.5),\n  logical = c(T, F, T, F, T),\n  date = lubridate::today()\n)\n\nwrite_sheet(data = letter_data, \n            ss = sheet_id, \n            sheet = \"letters\")\n\n## append some data\nnew_data <- tibble(\n  character = \"F\",\n  integer = 6L,\n  double = 6.6,\n  logical = FALSE,\n  date = lubridate::today()\n)\nsheet_append(data = new_data,\n             ss = sheet_id,\n             sheet = \"letters\")\n\n# read the data\ndemo <- read_sheet(ss = sheet_id, sheet = \"letters\")\n```\n:::\n\n\n\n::: {.callout-note .try}\n* Create a new table called `family` with the first name, last name, and age of your family members (biological, adopted, or chosen). \n* Save it to a CSV file called \"family.csv\". \n* Clear the object from your environment by restarting R or with the code `remove(family)`.\n* Load the data back in and view it.\n\n\n::: {.cell layout-align=\"center\" webex.hide='Solution'}\n::: {.callout-note collapse='true'}\n## Solution\n\n```{.r .cell-code}\n# create the table\nfamily <- tribble(\n  ~first_name, ~last_name, ~age,\n  \"Lisa\", \"DeBruine\", 45,\n  \"Robbie\", \"Jones\", 14\n)\n\n# save the data to CSV\nexport(family, \"data/family.csv\")\n\n# remove the object from the environment\nremove(family)\n\n# load the data\nfamily <- import(\"data/family.csv\")\n```\n\n:::\n:::\n\n:::\n\nWe'll be working with <a class='glossary'>tabular data<span class='def'></span></a> a lot in this class, but tabular data is made up of <a class='glossary'>vectors<span class='def'></span></a>, which groups together data with the same basic <a class='glossary'>data type<span class='def'></span></a>. @sec-data-types explains some of this terminology to help you understand the functions we'll be learning to process and analyse data.\n\n\n## Troubleshooting\n\nWhat if you import some data and it guesses the wrong column type? The most common reason is that a numeric column has some non-numbers in it somewhere. Maybe someone wrote a note in an otherwise numeric column. Columns have to be all one data type, so if there are any characters, the whole column is converted to character strings, and numbers like `1.2` get represented as `\"1.2\"`, which will cause very weird errors like `\"100\" < \"9\" == TRUE`. You can catch this by using `glimpse()` to check your data.\n\nThe data directory you downloaded contains a file called \"mess.csv\". Let's try loading this dataset.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmess <- rio::import(\"data/mess.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in (function (input = \"\", file = NULL, text = NULL, cmd = NULL, :\nStopped early on line 5. Expected 7 fields but found 0. Consider fill=TRUE and\ncomment.char=. First discarded non-empty line: <<junk,missing,0.72,b,1,2 -\n3,2020-01-2>>\n```\n:::\n:::\n\n\nWhen importing goes wrong, it's often easier to fix it using the  specific importing function for that file type (e.g., use `read_csv()` rather than `rio::import()`. This is because the problems tend to be specific to the file format and you can look up the help for these functions more easily. For CSV files, the import function is `readr::read_csv`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# lazy = FALSE loads the data right away so you can see error messages\n# this default changed in late 2021 and might change back soon\nmess <- read_csv(\"data/mess.csv\", lazy = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 27 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): This is my messy dataset\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\nYou'll get a warning about parsing issues and the data table is just a single column. View the file `data/mess.csv` by clicking on it in the File pane, and choosing \"View File\". Here are the first 10 lines. What went wrong?\n\n<div class=\"kable-table\">\n\n|This is my messy dataset                  |\n|:-----------------------------------------|\n|junk,order,score,letter,good,min_max,date |\n|junk,1,-1,a,1,1 - 2,2020-01-1             |\n|junk,missing,0.72,b,1,2 - 3,2020-01-2     |\n|junk,3,-0.62,c,FALSE,3 - 4,2020-01-3      |\n|junk,4,2.03,d,T,4 - 5,2020-01-4           |\n|junk,5,NA,e,1,5 - 6,2020-01-5             |\n\n</div>\n\nFirst, the file starts with a note: \"This is my messy dataset\" and then a blank line. The first line of data should be the column headings, so we want to skip the first two lines. You can do this with the argument `skip` in `read_csv()`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmess <- read_csv(\"data/mess.csv\", \n                 skip = 2,\n                 lazy = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 26 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): junk, order, letter, good, min_max, date\ndbl (1): score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nglimpse(mess)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 26\nColumns: 7\n$ junk    <chr> \"junk\", \"junk\", \"junk\", \"junk\", \"junk\", \"junk\", \"junk\", \"junk\"…\n$ order   <chr> \"1\", \"missing\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\",…\n$ score   <dbl> -1.00, 0.72, -0.62, 2.03, NA, 0.99, 0.03, 0.67, 0.57, 0.90, -1…\n$ letter  <chr> \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m…\n$ good    <chr> \"1\", \"1\", \"FALSE\", \"T\", \"1\", \"0\", \"T\", \"TRUE\", \"1\", \"T\", \"F\", …\n$ min_max <chr> \"1 - 2\", \"2 - 3\", \"3 - 4\", \"4 - 5\", \"5 - 6\", \"6 - 7\", \"7 - 8\",…\n$ date    <chr> \"2020-01-1\", \"2020-01-2\", \"2020-01-3\", \"2020-01-4\", \"2020-01-5…\n```\n:::\n:::\n\n\nOK, that's a little better, but this table is still a serious mess in several ways:\n\n* `junk` is a column that we don't need\n* `order` should be an integer column\n* `good` should be a logical column\n* `good` uses all kinds of different ways to record TRUE and FALSE values\n* `min_max` contains two pieces of numeric information, but is a character column\n* `date` should be a date column\n\nWe'll learn how to deal with this mess in @sec-tidy and @sec-wrangle, but we can fix a few things by setting the `col_types` argument in `read_csv()` to specify the column types for our two columns that were guessed wrong and skip the \"junk\" column. The argument `col_types` takes a list where the name of each item in the list is a column name and the value is from the table below. You can use the function, like `col_double()` or the abbreviation, like `\"d\"`; for consistency with earlier in this chapter we will use the function names. Omitted column names are guessed.\n\n| function | |abbreviation | type |\n|:---------|:--------------|:-----|\n| col_logical()   | l | logical values |\n| col_integer()   | i | integer values |\n| col_double()    | d | numeric values |\n| col_character() | c | strings |\n| col_factor(levels, ordered) | f | a fixed set of values |\n| col_date(format = \"\")     | D | with the locale's date_format |\n| col_time(format = \"\")     | t | with the locale's time_format |\n| col_datetime(format = \"\") | T | ISO8601 date time |\n| col_number()    | n | numbers containing the grouping_mark |\n| col_skip()      | _, - | don't import this column |\n| col_guess()     | ? | parse using the \"best\" type based on the input |\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# omitted values are guessed\n# ?col_date for format options\nct <- cols(\n  junk = col_skip(), # skip this column\n  order = col_integer(),\n  good = col_logical(),\n  date = col_date(format = \"%Y-%m-%d\")\n)\n\ntidier <- read_csv(\"data/mess.csv\", \n                   skip = 2,\n                   col_types = ct,\n                   lazy = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n:::\n:::\n\n\nYou will get a message about parsing issues when you run this that tells you to run the `problems()` function to see a table of the problems. Warnings look scary at first, but always start by reading the message.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nproblems()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| row| col|expected   |actual  |file          |\n|---:|---:|:----------|:-------|:-------------|\n|   3|   2|an integer |missing |data/mess.csv |\n\n</div>\n:::\n:::\n\n\n\nThe output of `problems()` tells you what row (3) and column (2) the error was found in, what kind of data was expected (an integer), and what the actual value was (missing). If you specifically tell `read_csv()` to import a column as an integer, any characters (i.e., not numbers) in the column will produce a warning like this and then be recorded as `NA`. You can manually set what missing values are recorded as with the `na` argument.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidiest <- read_csv(\"data/mess.csv\", \n                   skip = 2,\n                   na = \"missing\",\n                   col_types = ct,\n                   lazy = FALSE)\n```\n:::\n\n\n\nNow `order` is an integer variable where any empty cells contain `NA`. The variable `good` is a logical value, where `0` and `F` are converted to `FALSE`, while `1` and `T` are converted to `TRUE`. The variable `date` is a date type (adding leading zeros to the day). We'll learn in later chapters how to fix other problems, such as the `min_max` column containing two different types of data.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| order|score |letter |good  |min_max |date       |\n|-----:|:-----|:------|:-----|:-------|:----------|\n|     1|-1    |a      |TRUE  |1 - 2   |2020-01-01 |\n|    NA|0.72  |b      |TRUE  |2 - 3   |2020-01-02 |\n|     3|-0.62 |c      |FALSE |3 - 4   |2020-01-03 |\n|     4|2.03  |d      |TRUE  |4 - 5   |2020-01-04 |\n|     5|NA    |e      |TRUE  |5 - 6   |2020-01-05 |\n|     6|0.99  |f      |FALSE |6 - 7   |2020-01-06 |\n\n</div>\n:::\n:::\n\n\n\n## Working with real data\n\nIt's worth highlighting at this point that working with real data can be difficult because each dataset can be messy in its own way. Throughout this course we will show you common errors and how to fix them, but be prepared that when you start with working your own data, you'll likely come across problems we don't cover in the course and that's just part of joy of learning programming. You'll also get better at looking up solutions using sites like [Stack Overflow](https://stackoverflow.com/) and there's a fantastic [#rstats](https://twitter.com/hashtag/rstats) community on Twitter you can ask for help.\n\nYou may also be tempted to fix messy datasets by, for example, opening up Excel and editing them there. Whilst this might seem easier in the short term, there's two serious issues with doing this. First, you will likely work with datasets that have recurring messy problems. By taking the time to solve these problems with code, you can apply the same solutions to a large number of future datasets so it's more efficient in the long run. Second, if you edit the spreadsheet, there's no record of what you did. By solving these problems with code, you do so reproducibly and you don't edit the original data file. This means that if you make an error, you haven't lost the original data and can recover.\n\n## Exercises\n\nFor the final step in this chapter, we will create a report using one of the in-built datasets to practice the skills you have used so far. You may need to refer back to previous chapters to help you complete these exercises and you may also want to take a break before you work through this section. We'd also recommend you knit at every step so that you can see how your output changes.\n\n### New Markdown {#sec-exercises-new-rmd-4}\n\nCreate and save a new R Markdown document named `starwars_report.Rmd`. In the set-up code chunk load the packages `tidyverse` and `rio`.\n\nWe're going to use the built-in `starwars` dataset that contains data about Star Wars characters. You can learn more about the dataset by using the `?help` function.\n\n### Import and export the dataset {#sec-exercises-load}\n\n* First, load the in-built dataset into the environment. Type and run the code to do this in the console; do not save it in your Markdown.  \n* Then, export the dataset to a .csv file and save it in your `data` directory. Again, do this in the console.\n* Finally, import this version of the dataset using `read_csv()` to an object named `starwars` - you can put this code in your Markdown.\n\n\n<div class='webex-solution'><button>Solution</button>\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata(starwars)\nexport(starwars, \"data/starwars.csv\")\nstarwars <- read_csv(\"data/starwars.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 87 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (11): name, hair_color, skin_color, eye_color, sex, gender, homeworld, s...\ndbl  (3): height, mass, birth_year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\n\n</div>\n\n\n### Convert column types\n\n* Check the column specification of `starwars`.\n* Create a new column specification that lists the following columns as factors: `hair_color`, `skin_color`, `eye_color`, `sex`, `gender`, `homeworld`, and `species` and skips the following columns: `films`, `vehicles`, and `starships` (this is because these columns contain multiple values and are stored as lists, which we haven't covered how to work with). You do not have to set the factor orders (although you can if you wish).\n* Re-import the dataset, this time with the corrected column types.\n\n\n<div class='webex-solution'><button>Solution</button>\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nspec(starwars)\ncorrected_cols <- cols(\n  name = col_character(),\n  height = col_double(),\n  mass = col_double(),\n  hair_color = col_factor(),\n  skin_color = col_factor(),\n  eye_color = col_factor(),\n  birth_year = col_double(),\n  sex = col_factor(),\n  gender = col_factor(),\n  homeworld = col_factor(),\n  species = col_factor(),\n  films = col_skip(),\n  vehicles = col_skip(),\n  starships = col_skip()\n)\n\nstarwars <- read_csv(\"data/starwars.csv\", col_types = corrected_cols)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncols(\n  name = col_character(),\n  height = col_double(),\n  mass = col_double(),\n  hair_color = col_character(),\n  skin_color = col_character(),\n  eye_color = col_character(),\n  birth_year = col_double(),\n  sex = col_character(),\n  gender = col_character(),\n  homeworld = col_character(),\n  species = col_character(),\n  films = col_character(),\n  vehicles = col_character(),\n  starships = col_character()\n)\n```\n:::\n:::\n\n\n\n</div>\n\n\n### Plots {#sec-exercises-plots}\n\nProduce the following plots and one plot of your own choosing. Write a brief summary of what each plot shows and any conclusions you might reach from the data. \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](app-import_files/figure-html/unnamed-chunk-25-1.png){fig-align='center' width=100%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](app-import_files/figure-html/unnamed-chunk-26-1.png){fig-align='center' width=100%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](app-import_files/figure-html/unnamed-chunk-27-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n<div class='webex-solution'><button>Solution</button>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(starwars, aes(height)) +\n  geom_histogram(binwidth = 25, colour = \"black\", alpha = .3) +\n  scale_x_continuous(breaks = seq(from = 50, to = 300, by = 25)) +\n  labs(title = \"Height (cm) distribution of Star Wars Characters\") +\n  theme_classic()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(starwars, aes(height, mass)) +\n  geom_point() +\n  labs(title = \"Mass (kg) by height (cm) distribution of Star Wars Characters\") +\n  theme_classic() +\n  scale_x_continuous(breaks = seq(from = 0, to = 300, by = 50)) +\n  scale_y_continuous(breaks = seq(from = 0, to = 2000, by = 100)) +\n  coord_cartesian(xlim = c(0, 300))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(starwars, aes(x = gender, fill = gender)) +\n  geom_bar(show.legend = FALSE, colour = \"black\") +\n  scale_x_discrete(name = \"Gender of character\", labels = (c(\"Masculine\", \"Feminine\", \"Missing\"))) +\n  scale_fill_brewer(palette = 2) +\n  labs(title = \"Number of Star Wars characters of each gender\") +\n  theme_bw()\n```\n:::\n\n\n\n</div>\n\n\n### Make it look nice\n\n* Add at least one Star Wars related image from an online source\n* Hide the code and any messages from the knitted output\n* Resize any images as you see fit\n\n\n<div class='webex-solution'><button>Solution</button>\n\n\n\n::: {.cell layout-align=\"center\" verbatim='r, echo = FALSE, out.width = \"50%\", fig.cap=\"Adaptation of Star Wars logo created by Weweje; original logo by Suzy Rice, 1976. CC-BY-3.0\"'}\n<div class='verbatim'><pre class='sourceCode r'><code class='sourceCode R'>&#96;&#96;&#96;{r, echo = FALSE, out.width = \"50%\", fig.cap=\"Adaptation of Star Wars logo created by Weweje; original logo by Suzy Rice, 1976. CC-BY-3.0\"}</code></pre>\n\n```{.r .cell-code}\nknitr::include_graphics(\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/Star_wars2.svg/2880px-Star_wars2.svg.png\")\n```\n\n<pre class='sourceCode r'><code class='sourceCode R'>&#96;&#96;&#96;</code></pre></div>\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Adaptation of Star Wars logo created by Weweje; original logo by Suzy Rice, 1976. CC-BY-3.0](https://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/Star_wars2.svg/2880px-Star_wars2.svg.png){fig-align='center' width=50%}\n:::\n:::\n\n\n\n\n</div>\n\n\n### Share your work\n\nOnce you're done, share your knitted html file on the Week 4 Teams channel so other learners on the course can see how you approached the task. \n\n\n\n\n\n## Glossary {#sec-glossary-data}\n\n\n::: {.cell layout-align=\"center\"}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:left;\"> definition </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> argument </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> character </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> console </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> data type </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> double </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> extension </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> global environment </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> integer </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> logical </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> NA </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> nominal </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> numeric </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> panes </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> tabular data </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> tidyverse </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> URL </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> vector </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n</tbody>\n</table>\n:::\n\n\n## Further resources {#sec-resources-data}\n\n* [Data import cheatsheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-import.pdf)\n* [Chapter 11: Data Import](http://r4ds.had.co.nz/data-import.html) in *R for Data Science*\n* [Multi-row headers](https://psyteachr.github.io/tutorials/multi-row-headers.html)\n\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "app-import_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}